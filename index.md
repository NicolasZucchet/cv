---
layout: cv
title: Nicolas Zucchet's CV
---

# Nicolas Zucchet
PhD student in artificial intelligence and computational neuroscience at ETH Zürich.

<div id="webaddress">
<a href="nzucchet@ethz.ch">nzucchet@ethz.ch</a>
| <a href="https://scholar.google.com/citations?user=cLhZY44AAAAJ&hl=fr">Google scholar</a>
| <a href="https://twitter.com/NicolasZucchet">Twitter</a>
</div>


## Education

`2021 - now` **PhD student**, *ETH Zürich, Switzerland*<br>
PhD candidate in artificial intelligence and computational neuroscience in the lab of Prof. Dr. Angelika Steger, jointly supervised by Dr. João Sacramento.

`2021` **Research internship**, *University of Bern, Switzerland*<br>
4 month research internship on probabilistic methods for continual learning, hosted by Prof. Dr. Jean-Pascal Pfister.

`2019 - 2021` **Master of Science Computer Science**, *ETH Zürich, Switzerland*<br>
Theoretical foundations of artificial intelligence (optimization, neuroscience, machine learning).<br>
Master thesis: “Equilibrium propagation for bilevel optimization”, supervised by Dr. João Sacramento.

`2016 - 2019` **Ingénieur polytechnicien (MSc)**, *École polytechnique, Palaiseau, France*<br>
Multidisciplinary education (applied mathematics, computer science, economics), specialization in deep learning and computer vision during the last two semesters.

`2014 - 2016` **Classe préparatoire aux grandes écoles (MPI\*)**, *Lycée Hoche, Versailles, France*<br>
Intensive trainining for competitive entrance exams to french Grandes Écoles (fundamental mathematics, computer science, physics).


## Industry experience

`2019` **Research intern**, *Prophesee, Paris, France*<br>
Deep learning algorithms for event-based cameras in autonomous cars.

`2018` **Software developer intern**, *Amadeus, Sofia-Antipolis, France*<br>
Design and development of continuous integration tools.


## Publications

### Preprints

`[2]` [Uncovering mesa-optimization algorithms in Transformers](https://arxiv.org/abs/2309.05858) <br>
J. von Oswald\*, E. Niklasson\*, M. Schlegel\*, S. Kobayashi, **N. Zucchet**, N. Scherrer, N. Miller, M. Sandler, B. Agüera y Arcas, M. Vladymyrov, R. Pascanu and J. Sacramento

`[1]` [Gated RNNs discover attention](https://arxiv.org/abs/2309.01775) <br>
**N. Zucchet**\*, S. Kobayashi\*, Y. Akram\*, J. von Oswald, M. Larcher, A. Steger<sup>†</sup>, J. Sacramento<sup>†</sup>

### Conference and journal papers

`[5]` [Online learning of long-range dependencies](https://arxiv.org/abs/2207.01332) <br>
**N. Zucchet**\*, R. Meier\*, S. Schug\*, A. Mujika and J. Sacramento <br>
*37th Conference on Neural Information Processing Systems (NeurIPS), 2023*

`[4]` [The least-control principle for learning at equilibrium](https://arxiv.org/abs/2207.01332) <br>
A. Meulemans\*, **N. Zucchet**\*, S. Kobayashi\*, J. von Oswald and J. Sacramento <br>
*36th Conference on Neural Information Processing Systems (NeurIPS), 2022* (selected as an oral)

`[3]` [A contrastive rule for meta-learning](https://arxiv.org/abs/2104.01677) <br>
**N. Zucchet**\*, S. Schug\*, J. von Oswald\*, D. Zhao and J. Sacramento <br>
*36th Conference on Neural Information Processing Systems (NeurIPS), 2022*

`[2]` [Beyond backpropagation: bilevel optimization through implicit differentiation and equilibrium propagation](https://arxiv.org/abs/2205.03076) <br>
**N. Zucchet** and J. Sacramento <br>
*Neural Computation 34 (12), 2022*

`[1]` [Learning where to learn: Gradient sparsity in meta and continual learning](https://proceedings.neurips.cc/paper/2021/file/2a10665525774fa2501c2c8c4985ce61-Paper.pdf) <br>
J. von Oswald\*, D. Zhao\*, S. Kobayashi, S. Schug, M. Caccia, **N. Zucchet** and J. Sacramento <br>
*35th Conference on Neural Information Processing Systems (NeurIPS), 2021*

### Workshop papers
`[1]` [Random initialisations performing above chance and how to find them](https://arxiv.org/abs/2209.07509) <br>
F. Benzing, S. Schug, R. Meier, J. von Oswald, Y. Akram, **N. Zucchet**, L. Aitchison<sup>†</sup>, A. Steger<sup>†</sup><br>
*OPT2022: 14th Annual Workshop on Optimization for Machine Learning (NeurIPS), 2022*


## Teaching

`Autumn 2022/2023` Teaching assistant for master’s course [Algorithms Lab](https://cadmo.ethz.ch/education/lectures/HS22/algolab/index.html).

`Spring 2022/2023` Teaching assistant for bachelor’s course [Algorithms and probability](https://cadmo.ethz.ch/education/lectures/FS22/AW/index.html).

`Autumn 2021` Teaching assistant for master’s course [Randomized algorithms and probabilistic methods](https://www.google.com/url?q=https%3A%2F%2Fcadmo.ethz.ch%2Feducation%2Flectures%2FHS21%2FRandAlg%2Findex.html&sa=D&sntz=1&usg=AOvVaw3htSHy9pCNap_11g9f3LBY).


## Community service

`2023` Reviewer for NeurIPS.

`2023` Reviewer for ICLR.

## Awards

`2022` NeurIPS 2022 Scholar Award
